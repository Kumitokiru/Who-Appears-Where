{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opv4FR32RYju"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spacy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Example\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy.training import Example\n",
        "from spacy.util import minibatch\n",
        "\n",
        "df = pd.read_csv('Friends_Journey_Dataset.csv')\n",
        "df.fillna(\"\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1PemnnESH3f"
      },
      "source": [
        "Preparing Training Data for NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "in1AXpgBSRRO"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    text = f\"Chapter {row['Chapter Number']}: {row['Narrative']} {row['Dialogue']}\"\n",
        "    character_names = row['Character Names'].split(\", \")  # Assumes names are comma-separated\n",
        "    entities = []\n",
        "\n",
        "    for name in character_names:\n",
        "        start = text.find(name)\n",
        "        if start != -1:\n",
        "            end = start + len(name)\n",
        "            entities.append((start, end, \"PERSON\"))  # Assign \"PERSON\" entity to character names\n",
        "\n",
        "    # Append only if at least one entity was found\n",
        "    if entities:\n",
        "        TRAIN_DATA.append((text, {\"entities\": entities}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeH43r4iSfeJ"
      },
      "source": [
        "Train the NER Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gSkOBNczShJT"
      },
      "outputs": [],
      "source": [
        "def remove_overlapping_entities(entities):\n",
        "    \"\"\"\n",
        "    Removes overlapping entity labels, keeping only the longest one.\n",
        "    \"\"\"\n",
        "    sorted_entities = sorted(entities, key=lambda x: (x[0], x[1] - x[0]))  # Sort by start index & length\n",
        "    non_overlapping = []\n",
        "    prev_end = -1\n",
        "\n",
        "    for start, end, label in sorted_entities:\n",
        "        if start >= prev_end:  # If it doesn't overlap with the previous entity\n",
        "            non_overlapping.append((start, end, label))\n",
        "            prev_end = end  # Update last used end position\n",
        "\n",
        "    return non_overlapping\n",
        "\n",
        "# Apply the function to clean training data\n",
        "for i, (text, annotations) in enumerate(TRAIN_DATA):\n",
        "    TRAIN_DATA[i][1][\"entities\"] = remove_overlapping_entities(annotations[\"entities\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih-_qv_BUPUi"
      },
      "source": [
        "TRAIN spaCy NER MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxcqUc4AUMfq",
        "outputId": "6ccf899f-94ed-4744-ee26-50c77428edf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Chapter 9:   Natapos ang intrams week na walamg na...\" with entities \"[(237, 243, 'PERSON'), (308, 313, 'PERSON'), (349,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Chapter 11: Mobile Legend Message From Annie    Se...\" with entities \"[(39, 44, 'PERSON'), (173, 179, 'PERSON'), (1143, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Chapter 35: At Gym            Crowd Chearing  Afte...\" with entities \"[(68, 73, 'PERSON'), (75, 80, 'PERSON'), (82, 88, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Chapter 46:                         Game Highlight...\" with entities \"[(269, 274, 'PERSON'), (1937, 1944, 'PERSON'), (19...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: {'ner': 5977.545335289811}\n",
            "Epoch 2, Loss: {'ner': 1769.3899074982414}\n",
            "Epoch 3, Loss: {'ner': 1745.5955682579163}\n",
            "Epoch 4, Loss: {'ner': 1714.1498022898377}\n",
            "Epoch 5, Loss: {'ner': 1520.959529358244}\n",
            "Epoch 6, Loss: {'ner': 1402.028978892928}\n",
            "Epoch 7, Loss: {'ner': 1247.7324987488578}\n",
            "Epoch 8, Loss: {'ner': 1145.1067579424878}\n",
            "Epoch 9, Loss: {'ner': 1082.5808384375887}\n",
            "Epoch 10, Loss: {'ner': 907.0083841790397}\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.blank(\"en\")  # Create a blank English model\n",
        "ner = nlp.add_pipe(\"ner\")  # Add Named Entity Recognizer component\n",
        "\n",
        "# Add PERSON label to the model\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations[\"entities\"]:\n",
        "        ner.add_label(\"PERSON\")\n",
        "\n",
        "# Begin training\n",
        "nlp.begin_training()\n",
        "\n",
        "# Train for 10 epochs\n",
        "for epoch in range(10):\n",
        "    losses = {}\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
        "        nlp.update([example], losses=losses)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {losses}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6siuC-3pV1jV"
      },
      "source": [
        "SAVE TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mli5uu4wV2HZ",
        "outputId": "b4a636c8-aff6-438a-e5c1-30d1f9278cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/Character_NER_Model\n"
          ]
        }
      ],
      "source": [
        "output_dir = \"/content/Character_NER_Model\"\n",
        "nlp.to_disk(output_dir)\n",
        "print(f\"Model saved to {output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djUhSZ-7W-Ao"
      },
      "source": [
        "TEST THE TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R97EHNpJW9JZ",
        "outputId": "bdd41897-6ce7-4953-d4e1-70fe2db7b550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Characters: [('Victor', 'PERSON')]\n"
          ]
        }
      ],
      "source": [
        "def predict_character_chapters(text):\n",
        "    \"\"\"\n",
        "    Given a text input, extracts character names using the trained model.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "# Example test\n",
        "test_text = \"Ethan and Victor went on an adventure.\"\n",
        "predicted_characters = predict_character_chapters(test_text)\n",
        "print(\"Predicted Characters:\", predicted_characters)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
